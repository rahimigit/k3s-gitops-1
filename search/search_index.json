{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home Cluster \u00b6 This repository is my home Kubernetes cluster in a declarative state. Flux watches my cluster folder and makes the changes to my cluster based on the YAML manifests. Feel free to open a Github issue or join the k8s@home Discord if you have any questions. This repository is built off the k8s-at-home/template-cluster-k3s repository. Cluster components \u00b6 rook-ceph : Provides persistent volumes, allowing any application to consume RBD block storage. Mozilla SOPS : Encrypts secrets which is safe to store - even to a public repository. cert-manager : Configured to create TLS certs for all ingress services automatically using LetsEncrypt. Kasten : Data backup and recovery Repository structure \u00b6 The Git repository contains the following directories under cluster and are ordered below by how Flux will apply them. base directory is the entrypoint to Flux crds directory contains custom resource definitions (CRDs) that need to exist globally in your cluster before anything else exists core directory (depends on crds ) are important infrastructure applications (grouped by namespace) that should never be pruned by Flux apps directory (depends on core ) is where your common applications (grouped by namespace) could be placed, Flux will prune resources here if they are not tracked by Git anymore ./cluster \u251c\u2500\u2500 ./apps \u251c\u2500\u2500 ./base \u251c\u2500\u2500 ./core \u2514\u2500\u2500 ./crds Automate all the things! \u00b6 Github Actions for checking code formatting Rancher System Upgrade Controller to apply updates to k3s Renovate with the help of the k8s-at-home/renovate-helm-releases Github action keeps my application charts and container images up-to-date Hardware \u00b6 Device Count OS Disk Size Data Disk Size Ram Purpose Thanks \u00b6 A lot of inspiration for my cluster came from the people that have shared their clusters over at awesome-home-kubernetes","title":"Introduction"},{"location":"#home-cluster","text":"This repository is my home Kubernetes cluster in a declarative state. Flux watches my cluster folder and makes the changes to my cluster based on the YAML manifests. Feel free to open a Github issue or join the k8s@home Discord if you have any questions. This repository is built off the k8s-at-home/template-cluster-k3s repository.","title":"Home Cluster"},{"location":"#cluster-components","text":"rook-ceph : Provides persistent volumes, allowing any application to consume RBD block storage. Mozilla SOPS : Encrypts secrets which is safe to store - even to a public repository. cert-manager : Configured to create TLS certs for all ingress services automatically using LetsEncrypt. Kasten : Data backup and recovery","title":"Cluster components"},{"location":"#repository-structure","text":"The Git repository contains the following directories under cluster and are ordered below by how Flux will apply them. base directory is the entrypoint to Flux crds directory contains custom resource definitions (CRDs) that need to exist globally in your cluster before anything else exists core directory (depends on crds ) are important infrastructure applications (grouped by namespace) that should never be pruned by Flux apps directory (depends on core ) is where your common applications (grouped by namespace) could be placed, Flux will prune resources here if they are not tracked by Git anymore ./cluster \u251c\u2500\u2500 ./apps \u251c\u2500\u2500 ./base \u251c\u2500\u2500 ./core \u2514\u2500\u2500 ./crds","title":"Repository structure"},{"location":"#automate-all-the-things","text":"Github Actions for checking code formatting Rancher System Upgrade Controller to apply updates to k3s Renovate with the help of the k8s-at-home/renovate-helm-releases Github action keeps my application charts and container images up-to-date","title":"Automate all the things!"},{"location":"#hardware","text":"Device Count OS Disk Size Data Disk Size Ram Purpose","title":"Hardware"},{"location":"#thanks","text":"A lot of inspiration for my cluster came from the people that have shared their clusters over at awesome-home-kubernetes","title":"Thanks"},{"location":"restore/","text":"Restoring after a cluster failure or rebuild \u00b6 Restoring Flux state \u00b6 1. Locate cluster GPG key \u00b6 export GPG_TTY = $( tty ) export FLUX_KEY_NAME = \"56k prod cluster (Flux) <email>\" gpg --list-secret-keys \" ${ FLUX_KEY_NAME } \" # pub rsa4096 2021-03-11 [SC] # 772154FFF783DE317KLCA0EC77149AC618D75581 # uid [ultimate] 56k prod cluster (Flux) <email> # sub rsa4096 2021-03-11 [E] export FLUX_KEY_FP = 772154FFF783DE317KLCA0EC77149AC618D75581 2. Verify cluster is ready for Flux \u00b6 flux --kubeconfig = ./kubeconfig check --pre # \u25ba checking prerequisites # \u2714 kubectl 1.21.0 >=1.18.0-0 # \u2714 Kubernetes 1.20.5+k3s1 >=1.16.0-0 # \u2714 prerequisites checks passed 3. Pre-create the flux-system namespace \u00b6 kubectl --kubeconfig = ./kubeconfig create namespace flux-system --dry-run = client -o yaml | kubectl --kubeconfig = ./kubeconfig apply -f - 4. Add the Flux GPG key in-order for Flux to decrypt SOPS secrets \u00b6 gpg --export-secret-keys --armor \" ${ FLUX_KEY_FP } \" | kubectl --kubeconfig = ./kubeconfig create secret generic sops-gpg \\ --namespace = flux-system \\ --from-file = sops.asc = /dev/stdin 5. Install Flux \u00b6 Due to race conditions with the Flux CRDs you will have to run the below command twice. There should be no errors on this second run. kubectl --kubeconfig = ./kubeconfig apply --kustomize = ./cluster/base/flux-system # namespace/flux-system configured # customresourcedefinition.apiextensions.k8s.io/alerts.notification.toolkit.fluxcd.io created # customresourcedefinition.apiextensions.k8s.io/buckets.source.toolkit.fluxcd.io created # customresourcedefinition.apiextensions.k8s.io/gitrepositories.source.toolkit.fluxcd.io created # customresourcedefinition.apiextensions.k8s.io/helmcharts.source.toolkit.fluxcd.io created # customresourcedefinition.apiextensions.k8s.io/helmreleases.helm.toolkit.fluxcd.io created # customresourcedefinition.apiextensions.k8s.io/helmrepositories.source.toolkit.fluxcd.io created # customresourcedefinition.apiextensions.k8s.io/kustomizations.kustomize.toolkit.fluxcd.io created # customresourcedefinition.apiextensions.k8s.io/providers.notification.toolkit.fluxcd.io created # customresourcedefinition.apiextensions.k8s.io/receivers.notification.toolkit.fluxcd.io created # serviceaccount/helm-controller created # serviceaccount/kustomize-controller created # serviceaccount/notification-controller created # serviceaccount/source-controller created # clusterrole.rbac.authorization.k8s.io/crd-controller-flux-system created # clusterrolebinding.rbac.authorization.k8s.io/cluster-reconciler-flux-system created # clusterrolebinding.rbac.authorization.k8s.io/crd-controller-flux-system created # service/notification-controller created # service/source-controller created # service/webhook-receiver created # deployment.apps/helm-controller created # deployment.apps/kustomize-controller created # deployment.apps/notification-controller created # deployment.apps/source-controller created # unable to recognize \"./cluster/base/flux-system\": no matches for kind \"Kustomization\" in version \"kustomize.toolkit.fluxcd.io/v1beta1\" # unable to recognize \"./cluster/base/flux-system\": no matches for kind \"GitRepository\" in version \"source.toolkit.fluxcd.io/v1beta1\" # unable to recognize \"./cluster/base/flux-system\": no matches for kind \"HelmRepository\" in version \"source.toolkit.fluxcd.io/v1beta1\" # unable to recognize \"./cluster/base/flux-system\": no matches for kind \"HelmRepository\" in version \"source.toolkit.fluxcd.io/v1beta1\" # unable to recognize \"./cluster/base/flux-system\": no matches for kind \"HelmRepository\" in version \"source.toolkit.fluxcd.io/v1beta1\" # unable to recognize \"./cluster/base/flux-system\": no matches for kind \"HelmRepository\" in version \"source.toolkit.fluxcd.io/v1beta1\" at this point after reconciliation Flux state should be restored. Restoring PVCs using Kasten \u00b6 Recovering from a K10 backup involves the following sequence of actions: 1. Create a Kubernetes Secret, k10-dr-secret, using the passphrase provided while enabling DR \u00b6 kubectl create secret generic k10-dr-secret \\ --namespace kasten-io \\ --from-literal key = <passphrase> 2. Install a fresh K10 instance \u00b6 Ensure that Flux has correctly deployed K10 to it's namespace kasten-io 3. Provide bucket information and credentials for the object storage location \u00b6 Ensure that Flux has correctly deployed the minio storage profile and that it's accessible within K10 4. Restoring the K10 backup \u00b6 Install the helm chart that creates the K10 restore job and wait for completion of the k10-restore job helm install k10-restore kasten/k10restore --namespace = kasten-io \\ --set sourceClusterID = <source-clusterID> \\ --set profile.name = <location-profile-name> 5. Application recovery \u00b6 Upon completion of the DR Restore job, go to the Applications card, select Removed under the Filter by status drop-down menu. Click restore under the application and select a restore point to recover from.","title":"Restore"},{"location":"restore/#restoring-after-a-cluster-failure-or-rebuild","text":"","title":"Restoring after a cluster failure or rebuild"},{"location":"restore/#restoring-flux-state","text":"","title":"Restoring Flux state"},{"location":"restore/#1-locate-cluster-gpg-key","text":"export GPG_TTY = $( tty ) export FLUX_KEY_NAME = \"56k prod cluster (Flux) <email>\" gpg --list-secret-keys \" ${ FLUX_KEY_NAME } \" # pub rsa4096 2021-03-11 [SC] # 772154FFF783DE317KLCA0EC77149AC618D75581 # uid [ultimate] 56k prod cluster (Flux) <email> # sub rsa4096 2021-03-11 [E] export FLUX_KEY_FP = 772154FFF783DE317KLCA0EC77149AC618D75581","title":"1. Locate cluster GPG key"},{"location":"restore/#2-verify-cluster-is-ready-for-flux","text":"flux --kubeconfig = ./kubeconfig check --pre # \u25ba checking prerequisites # \u2714 kubectl 1.21.0 >=1.18.0-0 # \u2714 Kubernetes 1.20.5+k3s1 >=1.16.0-0 # \u2714 prerequisites checks passed","title":"2. Verify cluster is ready for Flux"},{"location":"restore/#3-pre-create-the-flux-system-namespace","text":"kubectl --kubeconfig = ./kubeconfig create namespace flux-system --dry-run = client -o yaml | kubectl --kubeconfig = ./kubeconfig apply -f -","title":"3. Pre-create the flux-system namespace"},{"location":"restore/#4-add-the-flux-gpg-key-in-order-for-flux-to-decrypt-sops-secrets","text":"gpg --export-secret-keys --armor \" ${ FLUX_KEY_FP } \" | kubectl --kubeconfig = ./kubeconfig create secret generic sops-gpg \\ --namespace = flux-system \\ --from-file = sops.asc = /dev/stdin","title":"4. Add the Flux GPG key in-order for Flux to decrypt SOPS secrets"},{"location":"restore/#5-install-flux","text":"Due to race conditions with the Flux CRDs you will have to run the below command twice. There should be no errors on this second run. kubectl --kubeconfig = ./kubeconfig apply --kustomize = ./cluster/base/flux-system # namespace/flux-system configured # customresourcedefinition.apiextensions.k8s.io/alerts.notification.toolkit.fluxcd.io created # customresourcedefinition.apiextensions.k8s.io/buckets.source.toolkit.fluxcd.io created # customresourcedefinition.apiextensions.k8s.io/gitrepositories.source.toolkit.fluxcd.io created # customresourcedefinition.apiextensions.k8s.io/helmcharts.source.toolkit.fluxcd.io created # customresourcedefinition.apiextensions.k8s.io/helmreleases.helm.toolkit.fluxcd.io created # customresourcedefinition.apiextensions.k8s.io/helmrepositories.source.toolkit.fluxcd.io created # customresourcedefinition.apiextensions.k8s.io/kustomizations.kustomize.toolkit.fluxcd.io created # customresourcedefinition.apiextensions.k8s.io/providers.notification.toolkit.fluxcd.io created # customresourcedefinition.apiextensions.k8s.io/receivers.notification.toolkit.fluxcd.io created # serviceaccount/helm-controller created # serviceaccount/kustomize-controller created # serviceaccount/notification-controller created # serviceaccount/source-controller created # clusterrole.rbac.authorization.k8s.io/crd-controller-flux-system created # clusterrolebinding.rbac.authorization.k8s.io/cluster-reconciler-flux-system created # clusterrolebinding.rbac.authorization.k8s.io/crd-controller-flux-system created # service/notification-controller created # service/source-controller created # service/webhook-receiver created # deployment.apps/helm-controller created # deployment.apps/kustomize-controller created # deployment.apps/notification-controller created # deployment.apps/source-controller created # unable to recognize \"./cluster/base/flux-system\": no matches for kind \"Kustomization\" in version \"kustomize.toolkit.fluxcd.io/v1beta1\" # unable to recognize \"./cluster/base/flux-system\": no matches for kind \"GitRepository\" in version \"source.toolkit.fluxcd.io/v1beta1\" # unable to recognize \"./cluster/base/flux-system\": no matches for kind \"HelmRepository\" in version \"source.toolkit.fluxcd.io/v1beta1\" # unable to recognize \"./cluster/base/flux-system\": no matches for kind \"HelmRepository\" in version \"source.toolkit.fluxcd.io/v1beta1\" # unable to recognize \"./cluster/base/flux-system\": no matches for kind \"HelmRepository\" in version \"source.toolkit.fluxcd.io/v1beta1\" # unable to recognize \"./cluster/base/flux-system\": no matches for kind \"HelmRepository\" in version \"source.toolkit.fluxcd.io/v1beta1\" at this point after reconciliation Flux state should be restored.","title":"5. Install Flux"},{"location":"restore/#restoring-pvcs-using-kasten","text":"Recovering from a K10 backup involves the following sequence of actions:","title":"Restoring PVCs using Kasten"},{"location":"restore/#1-create-a-kubernetes-secret-k10-dr-secret-using-the-passphrase-provided-while-enabling-dr","text":"kubectl create secret generic k10-dr-secret \\ --namespace kasten-io \\ --from-literal key = <passphrase>","title":"1. Create a Kubernetes Secret, k10-dr-secret, using the passphrase provided while enabling DR"},{"location":"restore/#2-install-a-fresh-k10-instance","text":"Ensure that Flux has correctly deployed K10 to it's namespace kasten-io","title":"2. Install a fresh K10 instance"},{"location":"restore/#3-provide-bucket-information-and-credentials-for-the-object-storage-location","text":"Ensure that Flux has correctly deployed the minio storage profile and that it's accessible within K10","title":"3. Provide bucket information and credentials for the object storage location"},{"location":"restore/#4-restoring-the-k10-backup","text":"Install the helm chart that creates the K10 restore job and wait for completion of the k10-restore job helm install k10-restore kasten/k10restore --namespace = kasten-io \\ --set sourceClusterID = <source-clusterID> \\ --set profile.name = <location-profile-name>","title":"4. Restoring the K10 backup"},{"location":"restore/#5-application-recovery","text":"Upon completion of the DR Restore job, go to the Applications card, select Removed under the Filter by status drop-down menu. Click restore under the application and select a restore point to recover from.","title":"5. Application recovery"}]}